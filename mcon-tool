#!/usr/bin/env python3

import sys
import argparse
import json
import csv
import logging
import copy
from collections import defaultdict

parser = argparse.ArgumentParser(description="Convert MCON files")
parser.add_argument("filename",nargs='?', default=None,help="file to convert")
parser.add_argument("--unnest",help="convert nested MCON -> non-nested MCON", action='store_true')
parser.add_argument("--atomize",help="split nested values", action='store_true')
#parser.add_argument("--nest",help="convert non-nested MCON -> nested MCON", action='store_true')
parser.add_argument("-O","--output",default="MCON",help="output format")
args = parser.parse_args()

def is_nested_key(key):
    assert(isinstance(key,str))
    if len(key) > 0 and key.endswith('/'):
        return True
    else:
        return False

def get_keys_non_nested(sample):
    keys = set()
    for key in sample:
        keys.add(key)
    return keys

def get_keys_nested(sample):
    keys = set()
    for key in sample:
        if is_nested_key(key):
            keys2 = get_keys_nested(sample[key])
            for key2 in keys2:
                keys.add(key + key2)
        else:
            keys.add(key)
    return keys


def get_long_names_and_values_data(prefix, value):
    d = dict()
    if isinstance(value,dict):
        for k,v in value.items():
            d.update(get_long_names_and_values_data(prefix+'['+k+']', v))
    elif isinstance(value,list):
        for i in range(len(value)):
            d.update(get_long_names_and_values_data(prefix+'['+str(i+1)+']', value[i]))
    else:
        d[prefix] = value
    return d

def atomize(sample, nested):
    sample2 = dict()

    for k,v in sample.items():
        if nested and is_nested_key(k):
            sample3 = dict()
            for k2,v2 in atomize(v,True).items():
                sample3[k2] = v2
            sample2[k] = sample3
        else:
            sample2.update(get_long_names_and_values_data(k,v))

    return sample2

def unnest(sample, prefix=""):
    sample2 = dict()
    for k,v in sample.items():
        if is_nested_key(k):
            sample2.update(unnest(v,prefix+k))
        else:
            sample2[prefix+k] = v
    return sample2

def get_long_names_and_values(sample, nested):
    sample = unnest(sample)
    sample = atomize(sample,nested)
    print(samples2)
    exit(0)
    return sample2

def nest(d):
    d2 = dict()

    subgroups = defaultdict(dict)
    for k,v in d.items():
        if "/" in k:
            prefix,rest = k.split("/",1)
            prefix += "/"
            subgroups[prefix][rest] = v
        else:
            d2[k] = v

    for k,v in subgroups.items():
        d2[k] = nest(v)

    return d2

def chop_nested(k):
    if is_nested_key(k):
        return k[0:len(k)-1]
    else:
        return k

def simplify(m):
    m2 = dict()

    seen = defaultdict(int)

    # Mark keys as seen
    for k,v in m.items():
        seen[chop_nested(k)] += 1
        if is_nested_key(k):
            for k2 in v:
                seen[chop_nested(k2)] += 1

    for k,v in m.items():
        if is_nested_key(k):
            ok = True
            for k2 in v:
                if seen[k2] > 1:
                    ok = False
            if ok:
                m2.update(v)
            else:
                m2[k] = v
        else:
            m2[k] = v

    return m2

def shortFields(fields):
    # 1. Construct the mapping from short field names to position.
    m = dict()
    for i in range(len(fields)):
        m[fields[i]] = i

    m = unnest(simplify(nest(m)))

    # 2. Construct the ORDERED list of short field names.
    fields2 = ["" for i in range(len(fields))]
    for name,index in m.items():
        fields2[index] = name

    return fields2


class LogFile(object):
    def __init__(self, header, samples):
        self.fields = header.get("fields",None)
        self.nested = header.get("nested",True)
        self.atomic = header.get("atomic",False)
        self.samples = samples

    def is_nested(self):
        return self.nested

    def is_atomic(self):
        return self.atomic

    def dump_MCON(self,**kwargs):
        header = dict()
        if self.fields is not None:
            header["fields"] = self.fields
        header["format"] = "MCON"
        header["version"] = "0.1"
        header["nested"] = self.nested
        header["atomic"] = self.atomic
        print(json.dumps(header),**kwargs)
        for sample in self.samples:
            print(json.dumps(sample),**kwargs)

    def get_keys(self):
        if self.nested:
            return get_keys_nested(self.samples[0])
        else:
            return get_keys_non_nested(self.samples[0])

    def unnest(self):
        if self.is_nested():
            logging.debug("Unnesting samples")
            samples2 = []
            for sample in self.samples:
                samples2.append(unnest(sample))
            self.samples = samples2
            self.nested = False

    def atomize(self):
        if not self.atomic:
            logging.debug("Atomizing samples")
            samples2 = []
            for sample in self.samples:
                samples2.append(atomize(sample,self.nested))
                self.samples = samples2
                self.atomic = True

    def dump_TSV(self,**kwargs):
        writer = csv.writer(kwargs["file"], delimiter='\t', quoting=csv.QUOTE_NONE)

        if not self.is_nested() and self.is_atomic():
            fields = []
            if self.fields is not None:
                fields = self.fields
            fields1=set(self.fields)
            all_fields = self.get_keys()

            for field in all_fields:
                if field not in fields1:
                    fields.append(field)

            nfields = len(fields)
            logging.debug(f"Writing TSV: {nfields} fields")

            printed_fields = fields
            if "shortNames" in kwargs and kwargs["shortNames"]:
                printed_fields = shortFields(fields)

            writer.writerow(printed_fields)

            for sample in self.samples:
                row = []
                for i in range(nfields):
                    row.append(json.dumps(sample[fields[i]]))
                writer.writerow(row)
        else:
            logfile = copy.deepcopy(self)
            logfile.unnest()
            logfile.atomize()
            if "shortNames" not in kwargs:
                kwargs["shortNames"] = True
            logfile.dump_TSV(**kwargs)

def detect_format(infile, filename):
    firstline = infile.readline().rstrip()
    # this shouldn't have any chars that need to be escaped in TSV.
    # assert( ??? )

    
    # want unquoted TSV.  Therefore, we can just read the first line 
    try:
        header = json.loads(firstline)
        logging.debug("JSON detected")
        if "format" in header and header["format"] == "MCON" and "version" in header:
            logging.debug("MCON detected")
            return ("MCON", firstline)
        else:
            # If this is JSON, then its not TSV
            logging.debug("Not an MCON file.")
            return None
    except Exception as e:
        logging.debug("TSV detected")
        logging.debug(f"exception {e}")
        return ("TSV", firstline)
    
def read_MCON(firstline,infile):
    logging.debug("reading MCON")
    header = json.loads(firstline)
    samples = []
    for line in infile:
        samples.append(json.loads(line))
    return LogFile(header, samples)

def read_TSV(firstline, infile):
    logging.debug("reading TSV")
    tsv_fields = firstline.split('\t')
    nfields = len(tsv_fields)

    header = dict()
    header["format"] = "MCON"
    header["version"] = "0.1"
    header["fields"] = tsv_fields
    header["nested"] = False

    reader = csv.reader(infile, delimiter="\t", quotechar='"')

    samples = []
    ignored_lines = 0;
    for tsv_line in reader:
        if len(tsv_line) != nfields:
            print(f"TSV line {1+len(samples)} has {len(tsv_line)} fields, but header has {nfields} fields.", file=sys.stderr)
            ignored_lines += 1
            break
        j = dict()
        for i in range(nfields):
            j[tsv_fields[i]] = json.loads(tsv_line[i])
        samples.append(j)

    for tsv_line in reader:
        ignored_lines += 1

    if ignored_lines > 0:
        print(f"Skipping the next {ignored_lines} lines.", file=sys.stderr)

    print(f"Read {len(samples)} samples of TSV with {len(header)} fields.", file=sys.stderr)
    return LogFile(header, samples)

def read_logfile(infile,filename):
    format, firstline  = detect_format(infile, filename)
    if format == "MCON":
        return read_MCON(firstline, infile)
    elif format == "TSV":
        return read_TSV(firstline, infile)
    elif format is None:
        print(f"Unknown format for file '{filename}'")
    else:
        print(f"Unknown format {format} for file '{filename}'")
    exit(1)

infile = sys.stdin
if args.filename is not None:
    infile = open(args.filename)

logfile = read_logfile(infile, args.filename)

if args.unnest:
    logfile.unnest()

if args.atomize:
    logfile.atomize()

if args.output == "tsv" or args.output == "TSV":
    logfile.dump_TSV(file=sys.stdout)
elif args.output == "mcon" or args.output == "MCON":
    logfile.dump_MCON(file=sys.stdout)
else:
    print(f"Error: Unrecognized output format '{args.output}'")
